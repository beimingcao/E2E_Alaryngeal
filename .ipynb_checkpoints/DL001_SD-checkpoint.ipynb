{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6431dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beiming/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.models import RegressionLoss\n",
    "from utils.models import save_model\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.utils import EarlyStopping, IterMeter, data_processing_DeepSpeech\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "from utils.transforms import apply_delta_deltadelta, Transform_Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.transforms import apply_MVN\n",
    "import torch.nn as nn\n",
    "from utils.utils import data_processing_DeepSpeech, GreedyDecoder\n",
    "from jiwer import wer\n",
    "from utils.database import Alaryngeal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122e5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.models import MyLSTM, SpeechRecognitionModel\n",
    "from utils.models import RegressionLoss\n",
    "from utils.models import save_model\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.utils import EarlyStopping, IterMeter, data_processing_DeepSpeech\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "from utils.transforms import ema_random_rotate, ema_time_mask, ema_freq_mask, ema_sin_noise, ema_random_scale, ema_time_seg_mask\n",
    "from utils.transforms import apply_delta_deltadelta, Transform_Compose\n",
    "from utils.transforms import apply_MVN\n",
    "import numpy as np\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eda4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_parsing(config, train_transform):\n",
    "\n",
    "    random_sin_noise_inj = config['data_augmentation']['random_sin_noise_inj']\n",
    "    random_rotate_apply = config['data_augmentation']['random_rotate']\n",
    "    random_time_mask = config['data_augmentation']['random_time_mask']\n",
    "    random_freq_mask = config['data_augmentation']['random_freq_mask']\n",
    "    random_scale = config['data_augmentation']['random_scale']\n",
    "    random_time_seg_mask = config['data_augmentation']['random_time_seg_mask']   \n",
    "    normalize_input = config['articulatory_data']['normalize_input']    \n",
    "\n",
    "    if random_sin_noise_inj == True:\n",
    "        ratio = config['random_sin_noise_inj']['ratio']\n",
    "        noise_energy_ratio = config['random_sin_noise_inj']['noise_energy_ratio']\n",
    "        noise_freq = config['random_sin_noise_inj']['noise_freq']\n",
    "        fs = 100\n",
    "        train_transform.append(ema_sin_noise(ratio, noise_energy_ratio, noise_freq, fs)) \n",
    "\n",
    "    if random_rotate_apply == True:\n",
    "        ratio = config['random_rotate']['ratio']\n",
    "        r_min = config['random_rotate']['r_min']\n",
    "        r_max = config['random_rotate']['r_max']\n",
    "        train_transform.append(ema_random_rotate(ratio,  [r_min, r_max])) \n",
    "\n",
    "    if random_scale == True:\n",
    "        ratio = config['random_scale']['ratio']\n",
    "        scale_min = config['random_scale']['scale_min']\n",
    "        scale_max = config['random_scale']['scale_max']\n",
    "        train_transform.append(ema_random_scale(ratio, scale_min, scale_max)) \n",
    "        \n",
    "    train_transform.append(apply_delta_deltadelta()) \n",
    "    \n",
    "    if normalize_input == True:\n",
    "        norm_transform = [apply_delta_deltadelta()]\n",
    "        norm_transforms_all = Transform_Compose(norm_transform)\n",
    "\n",
    "        train_loader_norm = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=1,\n",
    "                                    shuffle=True,\n",
    "                                    collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = norm_transforms_all))\n",
    "        EMA_all = {}\n",
    "        i = 0\n",
    "        for batch_idx, _data in enumerate(train_loader_norm):\n",
    "            file_id, EMA, labels, input_lengths, label_lengths = _data \n",
    "            ema = EMA[0][0].T\n",
    "            EMA_all[i] = ema\n",
    "            i+=1\n",
    "\n",
    "        EMA_block = np.concatenate([EMA_all[x] for x in EMA_all], 0)\n",
    "        EMA_mean, EMA_std  = np.mean(EMA_block, 0), np.std(EMA_block, 0)\n",
    "        \n",
    "        train_transform.append(apply_MVN(EMA_mean, EMA_std))\n",
    "\n",
    "    if random_time_mask == True:\n",
    "        ratio = config['random_time_mask']['ratio']\n",
    "        mask_num = config['random_time_mask']['mask_num']\n",
    "        train_transform.append(ema_time_mask(ratio, mask_num))\n",
    "\n",
    "    if random_freq_mask == True:\n",
    "        ratio = config['random_freq_mask']['ratio']\n",
    "        mask_num = config['random_freq_mask']['mask_num']\n",
    "        train_transform.append(ema_freq_mask(ratio, mask_num))\n",
    "\n",
    "    if random_time_seg_mask == True:\n",
    "        ratio = config['random_time_seg_mask']['ratio']\n",
    "        mask_num = config['random_time_seg_mask']['mask_num']\n",
    "        mask_length = config['random_time_seg_mask']['mask_length']\n",
    "        train_transform.append(ema_time_seg_mask(ratio, mask_num, mask_length))    \n",
    "        \n",
    "    return train_transform, EMA_mean, EMA_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7582dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a89b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "### Dimension setup ###\n",
    "config = yaml.load(open('conf/SSR_conf.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "sel_sensors = config['articulatory_data']['sel_sensors']\n",
    "sel_dim = config['articulatory_data']['sel_dim'] \n",
    "delta = config['articulatory_data']['delta']\n",
    "d = 3 if delta == True else 1\n",
    "D_in = len(sel_sensors)*len(sel_dim)*d\n",
    "D_out = 41\n",
    "\n",
    "### Model setup ###\n",
    "n_cnn_layers = config['deep_speech_setup']['n_cnn_layers']\n",
    "n_rnn_layers = config['deep_speech_setup']['n_rnn_layers']    \n",
    "rnn_dim = config['deep_speech_setup']['rnn_dim']\n",
    "stride = config['deep_speech_setup']['stride']\n",
    "dropout = config['deep_speech_setup']['dropout']\n",
    "\n",
    "### Training setup ###\n",
    "learning_rate = config['deep_speech_setup']['learning_rate']\n",
    "batch_size = config['deep_speech_setup']['batch_size']\n",
    "epochs = config['deep_speech_setup']['epochs']\n",
    "early_stop = config['deep_speech_setup']['early_stop']\n",
    "patient = config['deep_speech_setup']['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0dd25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.IO_func import read_file_list\n",
    "\n",
    "data_path = '/home/beiming/RAW_DATA/Haskins_IEEE'\n",
    "SPK = 'DL001'\n",
    "data_path_SPK = os.path.join(data_path, SPK)\n",
    "\n",
    "filesets_path = os.path.join(data_path, 'filesets')\n",
    "filesets_path_SPK = os.path.join(filesets_path, SPK)\n",
    "\n",
    "file_id_list = read_file_list(os.path.join(filesets_path_SPK, 'file_id_list.scp'))\n",
    "train_id_list = read_file_list(os.path.join(filesets_path_SPK, 'train_id_list.scp'))\n",
    "valid_id_list = read_file_list(os.path.join(filesets_path_SPK, 'valid_id_list.scp'))\n",
    "test_id_list = read_file_list(os.path.join(filesets_path_SPK, 'test_id_list.scp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ecc2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Alaryngeal_data(data_path, train_id_list, transforms = None)\n",
    "valid_dataset = Alaryngeal_data(data_path, valid_id_list, transforms = None)\n",
    "test_dataset = Alaryngeal_data(data_path, test_id_list, transforms = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04bbd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = []\n",
    "valid_transform = []\n",
    "\n",
    "train_transform, EMA_mean, EMA_std = augmentation_parsing(config, train_transform)\n",
    "\n",
    "valid_transform.append(apply_delta_deltadelta())\n",
    "valid_transform.append(apply_MVN(EMA_mean, EMA_std))\n",
    "\n",
    "train_transforms_all = Transform_Compose(train_transform)\n",
    "valid_transforms_all = Transform_Compose(valid_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = train_transforms_all))\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = valid_transforms_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0abfbda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying early stop.\n"
     ]
    }
   ],
   "source": [
    "model = SpeechRecognitionModel(n_cnn_layers, n_rnn_layers, rnn_dim, D_out, D_in, stride, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), learning_rate)\n",
    "criterion = torch.nn.CTCLoss(blank=40).to(device)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=int(len(train_loader)), epochs=epochs, anneal_strategy='linear')\n",
    "\n",
    "data_len = len(train_loader.dataset)\n",
    "if early_stop == True:\n",
    "    print('Applying early stop.')\n",
    "    early_stopping = EarlyStopping(patience=patient)\n",
    "\n",
    "iter_meter = IterMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10791c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_train = []\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        file_id, ema, labels, input_lengths, label_lengths = _data \n",
    "\n",
    "        ema, labels = ema.to(device), labels.to(device)\n",
    "\n",
    "        output = model(ema)  # (batch, time, n_class)\n",
    "\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "\n",
    "        loss_train.append(loss.detach().cpu().numpy())\n",
    "    avg_loss_train = sum(loss_train)/len(loss_train)\n",
    "\n",
    "    model.eval()\n",
    "    loss_valid = []\n",
    "    for batch_idx, _data in enumerate(valid_loader):  \n",
    "        file_id, ema, labels, input_lengths, label_lengths = _data \n",
    "        ema, labels = ema.to(device), labels.to(device)           \n",
    "\n",
    "        output = model(ema)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)    \n",
    "        loss_valid.append(loss.detach().cpu().numpy())\n",
    "    avg_loss_valid = sum(loss_valid)/len(loss_valid) \n",
    "    SPK = file_id[0][:3]\n",
    "\n",
    "    early_stopping(avg_loss_valid)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "\n",
    "    print('epoch %-3d \\t train_loss = %0.5f \\t valid_loss = %0.5f' % (epoch, avg_loss_train, avg_loss_valid))\n",
    "\n",
    "   # model_out_folder = os.path.join(exp_output_folder, 'trained_models')\n",
    "    model_out_folder = 'trained_models'\n",
    "    if not os.path.exists(model_out_folder):\n",
    "        os.makedirs(model_out_folder)\n",
    "    if early_stopping.save_model == True:\n",
    "        save_model(model, os.path.join(model_out_folder, 'DL001' + '_DS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a598c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
