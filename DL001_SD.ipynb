{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a44ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beiming/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.models import RegressionLoss\n",
    "from utils.models import save_model\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.utils import EarlyStopping, IterMeter, data_processing_DeepSpeech\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "from utils.transforms import apply_delta_deltadelta, Transform_Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.transforms import apply_MVN\n",
    "import torch.nn as nn\n",
    "from utils.utils import data_processing_DeepSpeech, GreedyDecoder\n",
    "from jiwer import wer\n",
    "from utils.database import Alaryngeal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c91200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.models import MyLSTM, SpeechRecognitionModel\n",
    "from utils.models import RegressionLoss\n",
    "from utils.models import save_model\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.utils import EarlyStopping, IterMeter, data_processing_DeepSpeech\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "from utils.transforms import ema_random_rotate, ema_time_mask, ema_freq_mask, ema_sin_noise, ema_random_scale, ema_time_seg_mask\n",
    "from utils.transforms import apply_delta_deltadelta, Transform_Compose\n",
    "from utils.transforms import apply_MVN\n",
    "import numpy as np\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92372837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_parsing(config, train_transform):\n",
    "\n",
    "    random_sin_noise_inj = config['data_augmentation']['random_sin_noise_inj']\n",
    "    random_rotate_apply = config['data_augmentation']['random_rotate']\n",
    "    random_time_mask = config['data_augmentation']['random_time_mask']\n",
    "    random_freq_mask = config['data_augmentation']['random_freq_mask']\n",
    "    random_scale = config['data_augmentation']['random_scale']\n",
    "    random_time_seg_mask = config['data_augmentation']['random_time_seg_mask']   \n",
    "    normalize_input = config['articulatory_data']['normalize_input']    \n",
    "\n",
    "    if random_sin_noise_inj == True:\n",
    "        ratio = config['random_sin_noise_inj']['ratio']\n",
    "        noise_energy_ratio = config['random_sin_noise_inj']['noise_energy_ratio']\n",
    "        noise_freq = config['random_sin_noise_inj']['noise_freq']\n",
    "        fs = 100\n",
    "        train_transform.append(ema_sin_noise(ratio, noise_energy_ratio, noise_freq, fs)) \n",
    "\n",
    "    if random_rotate_apply == True:\n",
    "        ratio = config['random_rotate']['ratio']\n",
    "        r_min = config['random_rotate']['r_min']\n",
    "        r_max = config['random_rotate']['r_max']\n",
    "        train_transform.append(ema_random_rotate(ratio,  [r_min, r_max])) \n",
    "\n",
    "    if random_scale == True:\n",
    "        ratio = config['random_scale']['ratio']\n",
    "        scale_min = config['random_scale']['scale_min']\n",
    "        scale_max = config['random_scale']['scale_max']\n",
    "        train_transform.append(ema_random_scale(ratio, scale_min, scale_max)) \n",
    "        \n",
    "    train_transform.append(apply_delta_deltadelta()) \n",
    "    \n",
    "    if normalize_input == True:\n",
    "        norm_transform = [apply_delta_deltadelta()]\n",
    "        norm_transforms_all = Transform_Compose(norm_transform)\n",
    "\n",
    "        train_loader_norm = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=1,\n",
    "                                    shuffle=True,\n",
    "                                    collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = norm_transforms_all))\n",
    "        EMA_all = {}\n",
    "        i = 0\n",
    "        for batch_idx, _data in enumerate(train_loader_norm):\n",
    "            file_id, EMA, labels, input_lengths, label_lengths = _data \n",
    "            ema = EMA[0][0].T\n",
    "            EMA_all[i] = ema\n",
    "            i+=1\n",
    "\n",
    "        EMA_block = np.concatenate([EMA_all[x] for x in EMA_all], 0)\n",
    "        EMA_mean, EMA_std  = np.mean(EMA_block, 0), np.std(EMA_block, 0)\n",
    "        \n",
    "        train_transform.append(apply_MVN(EMA_mean, EMA_std))\n",
    "\n",
    "    if random_time_mask == True:\n",
    "        ratio = config['random_time_mask']['ratio']\n",
    "        mask_num = config['random_time_mask']['mask_num']\n",
    "        train_transform.append(ema_time_mask(ratio, mask_num))\n",
    "\n",
    "    if random_freq_mask == True:\n",
    "        ratio = config['random_freq_mask']['ratio']\n",
    "        mask_num = config['random_freq_mask']['mask_num']\n",
    "        train_transform.append(ema_freq_mask(ratio, mask_num))\n",
    "\n",
    "    if random_time_seg_mask == True:\n",
    "        ratio = config['random_time_seg_mask']['ratio']\n",
    "        mask_num = config['random_time_seg_mask']['mask_num']\n",
    "        mask_length = config['random_time_seg_mask']['mask_length']\n",
    "        train_transform.append(ema_time_seg_mask(ratio, mask_num, mask_length))    \n",
    "        \n",
    "    return train_transform, EMA_mean, EMA_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93769548",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7750940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "### Dimension setup ###\n",
    "config = yaml.load(open('conf/SSR_conf.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "sel_sensors = config['articulatory_data']['sel_sensors']\n",
    "sel_dim = config['articulatory_data']['sel_dim'] \n",
    "delta = config['articulatory_data']['delta']\n",
    "d = 3 if delta == True else 1\n",
    "D_in = len(sel_sensors)*len(sel_dim)*d\n",
    "D_out = 41\n",
    "\n",
    "### Model setup ###\n",
    "n_cnn_layers = config['deep_speech_setup']['n_cnn_layers']\n",
    "n_rnn_layers = config['deep_speech_setup']['n_rnn_layers']    \n",
    "rnn_dim = config['deep_speech_setup']['rnn_dim']\n",
    "stride = config['deep_speech_setup']['stride']\n",
    "dropout = config['deep_speech_setup']['dropout']\n",
    "\n",
    "### Training setup ###\n",
    "learning_rate = config['deep_speech_setup']['learning_rate']\n",
    "batch_size = config['deep_speech_setup']['batch_size']\n",
    "epochs = config['deep_speech_setup']['epochs']\n",
    "early_stop = config['deep_speech_setup']['early_stop']\n",
    "patient = config['deep_speech_setup']['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c315ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.IO_func import read_file_list\n",
    "\n",
    "data_path = '/home/beiming/RAW_DATA/Haskins_IEEE'\n",
    "SPK = 'DL001'\n",
    "data_path_SPK = os.path.join(data_path, SPK)\n",
    "\n",
    "filesets_path = os.path.join(data_path, 'filesets')\n",
    "filesets_path_SPK = os.path.join(filesets_path, SPK)\n",
    "\n",
    "file_id_list = read_file_list(os.path.join(filesets_path_SPK, 'file_id_list.scp'))\n",
    "train_id_list = read_file_list(os.path.join(filesets_path_SPK, 'train_id_list.scp'))\n",
    "valid_id_list = read_file_list(os.path.join(filesets_path_SPK, 'valid_id_list.scp'))\n",
    "test_id_list = read_file_list(os.path.join(filesets_path_SPK, 'test_id_list.scp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75474586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Alaryngeal_data(data_path, train_id_list, transforms = None)\n",
    "valid_dataset = Alaryngeal_data(data_path, valid_id_list, transforms = None)\n",
    "test_dataset = Alaryngeal_data(data_path, test_id_list, transforms = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d4382a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = []\n",
    "valid_transform = []\n",
    "\n",
    "train_transform, EMA_mean, EMA_std = augmentation_parsing(config, train_transform)\n",
    "\n",
    "valid_transform.append(apply_delta_deltadelta())\n",
    "valid_transform.append(apply_MVN(EMA_mean, EMA_std))\n",
    "\n",
    "train_transforms_all = Transform_Compose(train_transform)\n",
    "valid_transforms_all = Transform_Compose(valid_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = train_transforms_all))\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = valid_transforms_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9570d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying early stop.\n"
     ]
    }
   ],
   "source": [
    "model = SpeechRecognitionModel(n_cnn_layers, n_rnn_layers, rnn_dim, D_out, D_in, stride, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), learning_rate)\n",
    "criterion = torch.nn.CTCLoss(blank=40).to(device)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=int(len(train_loader)), epochs=epochs, anneal_strategy='linear')\n",
    "\n",
    "data_len = len(train_loader.dataset)\n",
    "if early_stop == True:\n",
    "    print('Applying early stop.')\n",
    "    early_stopping = EarlyStopping(patience=patient)\n",
    "\n",
    "iter_meter = IterMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ed2a585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0   \t train_loss = 14.32792 \t valid_loss = 11.47437\n",
      "epoch 1   \t train_loss = 11.10949 \t valid_loss = 5.93669\n",
      "epoch 2   \t train_loss = 5.53574 \t valid_loss = 4.32457\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 3   \t train_loss = 4.24014 \t valid_loss = 5.99731\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 4   \t train_loss = 4.70192 \t valid_loss = 4.68415\n",
      "epoch 5   \t train_loss = 4.00821 \t valid_loss = 3.64048\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 6   \t train_loss = 3.72243 \t valid_loss = 3.72334\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 7   \t train_loss = 3.60166 \t valid_loss = 3.93245\n",
      "epoch 8   \t train_loss = 3.57489 \t valid_loss = 3.57667\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 9   \t train_loss = 3.51873 \t valid_loss = 3.61357\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 10  \t train_loss = 3.52181 \t valid_loss = 3.64482\n",
      "epoch 11  \t train_loss = 3.47954 \t valid_loss = 3.53833\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 12  \t train_loss = 3.47639 \t valid_loss = 3.58028\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 13  \t train_loss = 3.47823 \t valid_loss = 3.54012\n",
      "epoch 14  \t train_loss = 3.43866 \t valid_loss = 3.53099\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 15  \t train_loss = 3.45016 \t valid_loss = 3.55028\n",
      "epoch 16  \t train_loss = 3.42757 \t valid_loss = 3.47529\n",
      "epoch 17  \t train_loss = 3.39640 \t valid_loss = 3.39407\n",
      "epoch 18  \t train_loss = 3.37274 \t valid_loss = 3.36985\n",
      "epoch 19  \t train_loss = 3.31953 \t valid_loss = 3.31763\n",
      "epoch 20  \t train_loss = 3.24284 \t valid_loss = 3.30205\n",
      "epoch 21  \t train_loss = 3.18083 \t valid_loss = 3.26765\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 22  \t train_loss = 3.15400 \t valid_loss = 3.28053\n",
      "epoch 23  \t train_loss = 3.11880 \t valid_loss = 3.25575\n",
      "epoch 24  \t train_loss = 3.10802 \t valid_loss = 3.22607\n",
      "epoch 25  \t train_loss = 3.11902 \t valid_loss = 3.14010\n",
      "epoch 26  \t train_loss = 3.07134 \t valid_loss = 3.05141\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 27  \t train_loss = 3.05822 \t valid_loss = 3.05632\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 28  \t train_loss = 3.05916 \t valid_loss = 3.09158\n",
      "INFO: Early stopping counter 3 of 10\n",
      "epoch 29  \t train_loss = 3.04083 \t valid_loss = 3.12085\n",
      "INFO: Early stopping counter 4 of 10\n",
      "epoch 30  \t train_loss = 3.04803 \t valid_loss = 3.10071\n",
      "epoch 31  \t train_loss = 3.05748 \t valid_loss = 3.01737\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 32  \t train_loss = 3.04824 \t valid_loss = 3.14093\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 33  \t train_loss = 3.06705 \t valid_loss = 3.11017\n",
      "INFO: Early stopping counter 3 of 10\n",
      "epoch 34  \t train_loss = 3.02233 \t valid_loss = 3.12552\n",
      "INFO: Early stopping counter 4 of 10\n",
      "epoch 35  \t train_loss = 3.02186 \t valid_loss = 3.04020\n",
      "INFO: Early stopping counter 5 of 10\n",
      "epoch 36  \t train_loss = 2.97981 \t valid_loss = 3.02581\n",
      "INFO: Early stopping counter 6 of 10\n",
      "epoch 37  \t train_loss = 3.03008 \t valid_loss = 3.09509\n",
      "INFO: Early stopping counter 7 of 10\n",
      "epoch 38  \t train_loss = 3.00608 \t valid_loss = 3.03039\n",
      "epoch 39  \t train_loss = 3.01844 \t valid_loss = 3.00381\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 40  \t train_loss = 2.99750 \t valid_loss = 3.05716\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 41  \t train_loss = 2.96468 \t valid_loss = 3.09241\n",
      "INFO: Early stopping counter 3 of 10\n",
      "epoch 42  \t train_loss = 3.00398 \t valid_loss = 3.06224\n",
      "INFO: Early stopping counter 4 of 10\n",
      "epoch 43  \t train_loss = 3.00315 \t valid_loss = 3.02588\n",
      "epoch 44  \t train_loss = 2.96985 \t valid_loss = 3.00111\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 45  \t train_loss = 2.99937 \t valid_loss = 3.08099\n",
      "epoch 46  \t train_loss = 2.99841 \t valid_loss = 2.98878\n",
      "epoch 47  \t train_loss = 2.96944 \t valid_loss = 2.96715\n",
      "INFO: Early stopping counter 1 of 10\n",
      "epoch 48  \t train_loss = 2.97504 \t valid_loss = 3.04767\n",
      "INFO: Early stopping counter 2 of 10\n",
      "epoch 49  \t train_loss = 2.94288 \t valid_loss = 2.99961\n",
      "INFO: Early stopping counter 3 of 10\n",
      "epoch 50  \t train_loss = 2.95702 \t valid_loss = 3.01031\n",
      "INFO: Early stopping counter 4 of 10\n",
      "epoch 51  \t train_loss = 2.96547 \t valid_loss = 2.99354\n",
      "INFO: Early stopping counter 5 of 10\n",
      "epoch 52  \t train_loss = 2.98318 \t valid_loss = 2.96920\n",
      "INFO: Early stopping counter 6 of 10\n",
      "epoch 53  \t train_loss = 2.96804 \t valid_loss = 2.99203\n",
      "INFO: Early stopping counter 7 of 10\n",
      "epoch 54  \t train_loss = 2.96874 \t valid_loss = 2.99542\n",
      "INFO: Early stopping counter 8 of 10\n",
      "epoch 55  \t train_loss = 2.95553 \t valid_loss = 3.00845\n",
      "INFO: Early stopping counter 9 of 10\n",
      "epoch 56  \t train_loss = 2.94353 \t valid_loss = 3.01423\n",
      "INFO: Early stopping counter 10 of 10\n",
      "INFO: Early stopping\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_train = []\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        file_id, ema, labels, input_lengths, label_lengths = _data \n",
    "\n",
    "        ema, labels = ema.to(device), labels.to(device)\n",
    "\n",
    "        output = model(ema)  # (batch, time, n_class)\n",
    "\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "\n",
    "        loss_train.append(loss.detach().cpu().numpy())\n",
    "    avg_loss_train = sum(loss_train)/len(loss_train)\n",
    "\n",
    "    model.eval()\n",
    "    loss_valid = []\n",
    "    for batch_idx, _data in enumerate(valid_loader):  \n",
    "        file_id, ema, labels, input_lengths, label_lengths = _data \n",
    "        ema, labels = ema.to(device), labels.to(device)           \n",
    "\n",
    "        output = model(ema)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)    \n",
    "        loss_valid.append(loss.detach().cpu().numpy())\n",
    "    avg_loss_valid = sum(loss_valid)/len(loss_valid) \n",
    "    SPK = file_id[0][:3]\n",
    "\n",
    "    early_stopping(avg_loss_valid)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "\n",
    "    print('epoch %-3d \\t train_loss = %0.5f \\t valid_loss = %0.5f' % (epoch, avg_loss_train, avg_loss_valid))\n",
    "\n",
    "   # model_out_folder = os.path.join(exp_output_folder, 'trained_models')\n",
    "    model_out_folder = 'trained_models'\n",
    "    if not os.path.exists(model_out_folder):\n",
    "        os.makedirs(model_out_folder)\n",
    "    if early_stopping.save_model == True:\n",
    "        save_model(model, os.path.join(model_out_folder, 'DL001' + '_DS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "440ec3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = []\n",
    "test_transform.append(apply_delta_deltadelta())\n",
    "normalize_input = True\n",
    "if normalize_input == True:\n",
    "    norm_transform = [apply_delta_deltadelta()]\n",
    "    norm_transforms_all = Transform_Compose(norm_transform)\n",
    "\n",
    "    train_loader_norm = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = norm_transforms_all))\n",
    "\n",
    "    EMA_all = {}\n",
    "    i = 0\n",
    "    for batch_idx, _data in enumerate(train_loader_norm):\n",
    "        file_id, EMA, labels, input_lengths, label_lengths = _data \n",
    "        ema = EMA[0][0].T\n",
    "        EMA_all[i] = ema\n",
    "        i+=1\n",
    "\n",
    "    EMA_block = np.concatenate([EMA_all[x] for x in EMA_all], 0)\n",
    "    EMA_mean, EMA_std  = np.mean(EMA_block, 0), np.std(EMA_block, 0)\n",
    "\n",
    "    test_transform.append(apply_MVN(EMA_mean, EMA_std))\n",
    "\n",
    "test_transforms_all = Transform_Compose(test_transform)\n",
    "\n",
    "### Test ###\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=lambda x: data_processing_DeepSpeech(x, transforms = test_transforms_all))\n",
    "\n",
    "model_out_folder = 'trained_models'\n",
    "\n",
    "SPK_model_path = os.path.join(model_out_folder)\n",
    "model_path = os.path.join(SPK_model_path, 'DL001' + '_DS')\n",
    "model = SpeechRecognitionModel(n_cnn_layers, n_rnn_layers, rnn_dim, D_out, D_in, stride, dropout)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "pred = []\n",
    "label = []\n",
    "\n",
    "for batch_idx, _data in enumerate(test_loader):\n",
    "    fid, ema, labels, input_lengths, label_lengths = _data \n",
    "    ema, labels = ema, labels\n",
    "\n",
    "    output = model(ema)  # (batch, time, n_class)\n",
    "\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "\n",
    "    pred.append(' '.join(decoded_preds[0]))\n",
    "    label.append(' '.join(decoded_targets[0]))\n",
    "\n",
    "error = wer(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7aa14e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.378048780487805\n"
     ]
    }
   ],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e360e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
